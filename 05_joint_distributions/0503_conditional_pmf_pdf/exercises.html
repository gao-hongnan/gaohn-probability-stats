
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Exercises &#8212; Probability &amp; Statistics</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script src="../../_static/tabs.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"defeq": "\\overset{\\text{def}}{=}", "defa": "\\overset{\\text{(a)}}{=}", "defb": "\\overset{\\text{(b)}}{=}", "defc": "\\overset{\\text{(c)}}{=}", "defd": "\\overset{\\text{(d)}}{=}", "st": "\\mid", "mod": "\\mid", "S": "\\Omega", "s": "\\omega", "e": "\\exp", "P": "\\mathbb{P}", "R": "\\mathbb{R}", "expectation": "\\mathbb{E}", "v": "\\mathbf{v}", "a": "\\mathbf{a}", "b": "\\mathbf{b}", "c": "\\mathbf{c}", "u": "\\mathbf{u}", "w": "\\mathbf{w}", "x": "\\mathbf{x}", "y": "\\mathbf{y}", "z": "\\mathbf{z}", "0": "\\mathbf{0}", "1": "\\mathbf{1}", "A": "\\mathbf{A}", "B": "\\mathbf{B}", "C": "\\mathbf{C}", "E": "\\mathcal{F}", "eventA": "\\mathcal{A}", "lset": "\\left\\{", "rset": "\\right\\}", "lsq": "\\left[", "rsq": "\\right]", "lpar": "\\left(", "rpar": "\\right)", "lcurl": "\\left\\{", "rcurl": "\\right\\}", "pmf": "p_X", "pdf": "f_X", "pdftwo": "f_{X,Y}", "pdfjoint": "f_{\\mathbf{X}}", "pmfjointxy": "p_{X, Y}", "pdfjointxy": "f_{X, Y}", "cdf": "F_X", "pspace": "(\\Omega, \\mathcal{F}, \\mathbb{P})", "var": "\\operatorname{Var}", "std": "\\operatorname{Std}", "bern": "\\operatorname{Bernoulli}", "binomial": "\\operatorname{Binomial}", "geometric": "\\operatorname{Geometric}", "poisson": "\\operatorname{Poisson}", "uniform": "\\operatorname{Uniform}", "normal": "\\operatorname{Normal}", "gaussian": "\\operatorname{Gaussian}", "gaussiansymbol": "\\mathcal{N}", "exponential": "\\operatorname{Exponential}", "iid": "\\textbf{i.i.d.}", "and": "\\text{and}"}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Conditional Expectation and Variance" href="../0504_conditional_expectation_variance/intro.html" />
    <link rel="prev" title="Concept" href="concept.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Probability & Statistics</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter 1. Mathematical Preliminaries
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../01_mathematical_preliminaries/01_combinatorics.html">
   Permutations and Combinations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../01_mathematical_preliminaries/02_calculus.html">
   Calculus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../01_mathematical_preliminaries/exercises.html">
   Exercises
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter 2. Probability
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../02_probability/0202_probability_space.html">
   Probability Space
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../02_probability/0203_probability_axioms.html">
   Probability Axioms
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../02_probability/0204_conditional_probability.html">
   Conditional Probability
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../02_probability/0205_independence.html">
   Independence
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../02_probability/0206_bayes_theorem.html">
   Baye’s Theorem and the Law of Total Probability
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../02_probability/summary.html">
   Summary
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter 3. Discrete Random Variables
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../03_discrete_random_variables/0301_random_variables.html">
   Random Variables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../03_discrete_random_variables/0302_discrete_random_variables.html">
   Discrete Random Variables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../03_discrete_random_variables/0303_probability_mass_function.html">
   Probability Mass Function
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../03_discrete_random_variables/0304_cumulative_distribution_function.html">
   Cumulative Distribution Function
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../03_discrete_random_variables/0305_expectation.html">
   Expectation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../03_discrete_random_variables/0306_moments_and_variance.html">
   Moments and Variance
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../03_discrete_random_variables/0307_discrete_uniform_distribution_concept.html">
   Discrete Uniform Distribution
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03_discrete_random_variables/0307_discrete_uniform_distribution_implementation.html">
     Implementation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../03_discrete_random_variables/0308_bernoulli_distribution_concept.html">
   Bernoulli Distribution
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03_discrete_random_variables/0308_bernoulli_distribution_implementation.html">
     Implementation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../03_discrete_random_variables/iid.html">
   Independent and Identically Distributed (IID)
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../03_discrete_random_variables/0309_binomial_distribution_concept.html">
   Binomial Distribution
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03_discrete_random_variables/0309_binomial_distribution_implementation.html">
     Implementation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03_discrete_random_variables/0309_binomial_distribution_application.html">
     Real World Examples
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../03_discrete_random_variables/0310_geometric_distribution_concept.html">
   Geometric Distribution
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../03_discrete_random_variables/0311_poisson_distribution_concept.html">
   Poisson Distribution
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03_discrete_random_variables/0311_poisson_distribution_implementation.html">
     Implementation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../03_discrete_random_variables/summary.html">
   Important
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../03_discrete_random_variables/exercises.html">
   Exercises
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter 4. Continuous Random Variables
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../04_continuous_random_variables/from_discrete_to_continuous.html">
   From Discrete to Continuous
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../04_continuous_random_variables/0401_continuous_random_variables.html">
   Continuous Random Variables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../04_continuous_random_variables/0402_probability_density_function.html">
   Probability Density Function
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../04_continuous_random_variables/0403_expectation.html">
   Expectation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../04_continuous_random_variables/0404_moments_and_variance.html">
   Moments and Variance
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../04_continuous_random_variables/0405_cumulative_distribution_function.html">
   Cumulative Distribution Function
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../04_continuous_random_variables/0406_mean_median_mode.html">
   Mean, Median and Mode
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../04_continuous_random_variables/0407_continuous_uniform_distribution.html">
   Continuous Uniform Distribution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../04_continuous_random_variables/0408_exponential_distribution.html">
   Exponential Distribution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../04_continuous_random_variables/0409_gaussian_distribution.html">
   Gaussian Distribution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../04_continuous_random_variables/0410_skewness_and_kurtosis.html">
   Skewness and Kurtosis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../04_continuous_random_variables/0411_convolve_and_sum_of_random_variables.html">
   Convolution and Sum of Random Variables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../04_continuous_random_variables/0412_functions_of_random_variables.html">
   Functions of Random Variables
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter 5. Joint Distributions
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../from_single_variable_to_joint_distributions.html">
   From Single Variable to Joint Distributions
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../0501_joint_pmf_pdf/intro.html">
   Joint PMF and PDF
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../0501_joint_pmf_pdf/concept.html">
     Concept
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../0502_joint_expectation_and_correlation/intro.html">
   Joint Expectation and Correlation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../0502_joint_expectation_and_correlation/concept.html">
     Concept
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="intro.html">
   Conditional PMF and PDF
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="concept.html">
     Concept
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../0504_conditional_expectation_variance/intro.html">
   Conditional Expectation and Variance
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../0504_conditional_expectation_variance/concept.html">
     Concept
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../0504_conditional_expectation_variance/exercises.html">
     Exercises
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../0505_sum_of_random_variables/intro.html">
   Sum of Random Variables
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../0505_sum_of_random_variables/concept.html">
     Concept
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Machine Learning Algorithms
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../machine_learning_algorithms/generative/naive_bayes/naive_bayes_concept.html">
   Naive Bayes Concept
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../machine_learning_algorithms/generative/naive_bayes/naive_bayes_example_penguin.html">
   Example: Penguins Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../machine_learning_algorithms/generative/naive_bayes/naive_bayes_application_mnist.html">
   Naive Bayes Application (MNIST)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../machine_learning_algorithms/generative/naive_bayes/naive_bayes_implementation.html">
   Naives Bayes Implementation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  References and Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../references_and_resources/bibliography.html">
   Bibliography
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../references_and_resources/resources.html">
   Resources
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/gao-hongnan/gaohn-probability-stats"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/gao-hongnan/gaohn-probability-stats/issues/new?title=Issue%20on%20page%20%2F05_joint_distributions/0503_conditional_pmf_pdf/exercises.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/05_joint_distributions/0503_conditional_pmf_pdf/exercises.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#medical-diagnosis">
   Medical Diagnosis
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simplified-probit-model">
   Simplified Probit Model
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Exercises</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#medical-diagnosis">
   Medical Diagnosis
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simplified-probit-model">
   Simplified Probit Model
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="exercises">
<h1>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">#</a></h1>
<section id="medical-diagnosis">
<h2>Medical Diagnosis<a class="headerlink" href="#medical-diagnosis" title="Permalink to this headline">#</a></h2>
<p>This example is taken from <a class="reference external" href="https://d2l.ai/chapter_preliminaries/probability.html#an-example">Dive into Deep Learning, Section 2.6.5</a>.</p>
<p>Assume that a doctor administers an HIV test to a patient.
This test is fairly <strong>accurate</strong> and it fails only with <span class="math notranslate nohighlight">\(1\%\)</span> probability
if the patient is healthy but reporting him as diseased.
Moreover, it never fails to detect HIV if the patient actually has it.</p>
<p>In machine learning lingo, we can treat the diagnosis as a <strong>classifier</strong>. More concretely,
let <span class="math notranslate nohighlight">\(Y\)</span> be the ground truth label of the patient, in this case, <span class="math notranslate nohighlight">\(Y \in \{0, 1\}\)</span>,
where <span class="math notranslate nohighlight">\(0\)</span> (negative) indicates that the patient is healthy and <span class="math notranslate nohighlight">\(1\)</span> (positive)
indicates that the patient has HIV.</p>
<p>Let <span class="math notranslate nohighlight">\(\hat{Y}\)</span> be the hard label predicted by the test, i.e., <span class="math notranslate nohighlight">\(\hat{Y} \in \{0, 1\}\)</span>.</p>
<p>To keep the notation similar to the original example, denote the first test as <span class="math notranslate nohighlight">\(\hat{Y}_1\)</span> and the second test as <span class="math notranslate nohighlight">\(\hat{Y}_2\)</span>.</p>
<p>Then we can define the following to describe the relationship between <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(\hat{Y}\)</span>:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p>Conditional probability</p></th>
<th class="text-align:right head"><p><span class="math notranslate nohighlight">\(Y=1\)</span></p></th>
<th class="text-align:right head"><p><span class="math notranslate nohighlight">\(Y=0\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p><span class="math notranslate nohighlight">\(\mathbb{P}(\hat{Y} = 1 \mid Y)\)</span></p></td>
<td class="text-align:right"><p>1</p></td>
<td class="text-align:right"><p>0.01</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p><span class="math notranslate nohighlight">\(\mathbb{P}(\hat{Y} = 0 \mid Y)\)</span></p></td>
<td class="text-align:right"><p>0</p></td>
<td class="text-align:right"><p>0.99</p></td>
</tr>
</tbody>
</table>
<p>In machine learning, a similar way is to use a <strong>confusion matrix</strong>.</p>
<p>Indeed, the true positive in the above table is <span class="math notranslate nohighlight">\(100\%\)</span>, which means that if a patient
has HIV, the predictions will always predict correctly. Consequently, the false negative
is <span class="math notranslate nohighlight">\(0\%\)</span>. On the other hand, the false positive is <span class="math notranslate nohighlight">\(1\%\)</span>, which means that if a patient
is healthy but the predictions predict him as diseased, the probability is <span class="math notranslate nohighlight">\(1\%\)</span>. Consequently,
the true negative is <span class="math notranslate nohighlight">\(99\%\)</span>, which means that if a patient is healthy, the predictions
indeed predict correctly with <span class="math notranslate nohighlight">\(99\%\)</span> probability.</p>
<p>Note that the column sums are all 1 (but the row sums don’t),
since they are conditional probabilities.</p>
<p>For our first task, let’s compute the probability of the patient having HIV
if the (first) test (classifier) comes back (predicts) positive,</p>
<div class="math notranslate nohighlight">
\[
P(Y = 1 \mid \hat{Y}_1 = 1) = \frac{P(\hat{Y}_1 = 1 \mid Y = 1) P(Y = 1)}{P(\hat{Y}_1 = 1)}.
\]</div>
<p>Intuitively this is going to depend on how common the disease is,
since it affects the number of false alarms.</p>
<p>We further assume the prior probability of the patient having HIV is <span class="math notranslate nohighlight">\(0.0015\)</span>.</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(Y = 1) = 0.0015.
\]</div>
<p>Then we can invoke Bayes’ theorem,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
P(Y = 1 \mid \hat{Y}_1 = 1)
=&amp; \frac{P(\hat{Y}_1 = 1 \mid Y = 1) P(Y = 1)}{P(\hat{Y}_1 = 1)} \\
\end{aligned}
\end{split}\]</div>
<p>We already know <span class="math notranslate nohighlight">\(\mathbb{P}(\hat{Y}_1 = 1 \mid Y = 1) = 1\)</span> and <span class="math notranslate nohighlight">\(\mathbb{P}(Y = 1) = 0.0015\)</span>.
We just need to compute <span class="math notranslate nohighlight">\(\mathbb{P}(\hat{Y}_1 = 1)\)</span>, where we need to apply marginalization
<a class="reference internal" href="../0501_joint_pmf_pdf/concept.html#def-marginal-pmf-pdf">Definition 59</a> to determine.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}(\hat{Y}_1 = 1) =&amp; \mathbb{P}(\hat{Y}_1 = 1, Y = 1) + \mathbb{P}(\hat{Y}_1 = 1, Y = 0) \\
=&amp; \mathbb{P}(\hat{Y}_1 = 1 \mid Y = 1) \mathbb{P}(Y = 1) + \mathbb{P}(\hat{Y}_1 = 1 \mid Y = 0) \mathbb{P}(Y = 0) \\
=&amp; 1 \times 0.0015 + 0.01 \times 0.9985 \\
=&amp; 0.011485.
\end{aligned}
\end{split}\]</div>
<p>A point to note, <span class="math notranslate nohighlight">\(\mathbb{P}(\hat{Y}_1 = 1, Y = 1) + \mathbb{P}(\hat{Y}_1 = 1, Y = 0)\)</span> makes us the sum of the probabilities of the patient having HIV and not having HIV, respectively, while fixing <span class="math notranslate nohighlight">\(\hat{Y}_1 = 1\)</span>. This is the same as the marginal probability of <span class="math notranslate nohighlight">\(\hat{Y}_1 = 1\)</span>. And in turn we can use the law of total probability to compute the marginal probability of <span class="math notranslate nohighlight">\(\hat{Y}_1 = 1\)</span>.</p>
<p>This leads us to</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}(Y = 1 \mid \hat{Y}_1 = 1) =&amp; \frac{1 \times 0.0015}{0.011485} \\
=&amp; 0.1306.
\end{aligned}
\end{split}\]</div>
<p>In other words, there is only a <span class="math notranslate nohighlight">\(13.06\%\)</span> chance
that the patient actually has HIV,
despite using a very accurate test.
As we can see, probability can be counterintuitive.</p>
<p>What should a patient do upon receiving such terrifying news?
Likely, the patient would ask the physician
to administer another test to get clarity.
The second test has different characteristics
and it is not as good as the first one. You can think of it as using
a second type of classifier (i.e. a different model) to predict the label of the patient.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p>Conditional probability</p></th>
<th class="text-align:right head"><p><span class="math notranslate nohighlight">\(Y=1\)</span></p></th>
<th class="text-align:right head"><p><span class="math notranslate nohighlight">\(Y=0\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p><span class="math notranslate nohighlight">\(\mathbb{P}(\hat{Y}_2 = 1 \mid Y)\)</span></p></td>
<td class="text-align:right"><p>0.98</p></td>
<td class="text-align:right"><p>0.03</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p><span class="math notranslate nohighlight">\(\mathbb{P}(\hat{Y}_2 = 0 \mid Y)\)</span></p></td>
<td class="text-align:right"><p>0.02</p></td>
<td class="text-align:right"><p>0.97</p></td>
</tr>
</tbody>
</table>
<p>Unfortunately, the second test comes back positive, too.
Now our question becomes, what is the probability that the patient has HIV
given that both tests come back positive? Formally stated as below:</p>
<div class="math notranslate nohighlight" id="equation-eq-prob-hiv-both-tests">
<span class="eqno">(34)<a class="headerlink" href="#equation-eq-prob-hiv-both-tests" title="Permalink to this equation">#</a></span>\[
P(Y = 1 \mid \hat{Y}_1 = 1, \hat{Y}_2 = 1).
\]</div>
<p>As usual, we represent <a class="reference internal" href="#equation-eq-prob-hiv-both-tests">(34)</a> using Bayes’ theorem:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
P(Y = 1 \mid \hat{Y}_1 = 1, \hat{Y}_2 = 1)
=&amp; \frac{P(\hat{Y}_1 = 1, \hat{Y}_2 = 1 \mid Y = 1) P(Y = 1)}{P(\hat{Y}_1 = 1, \hat{Y}_2 = 1)} \\
\end{aligned}
\end{split}\]</div>
<p>Now, <span class="math notranslate nohighlight">\(\mathbb{P}(\hat{Y}_1 = 1, \hat{Y}_2 = 1 \mid Y = 1)\)</span> is the probability that both tests come back positive given that the patient has HIV. This involves the joint probability of the two tests, and is not easily computed. Instead, we can use the conditional independence assumption to simplify the computation. More concretely,
we assume that <span class="math notranslate nohighlight">\(\hat{Y}_1\)</span> and <span class="math notranslate nohighlight">\(\hat{Y}_2\)</span> are independent given <span class="math notranslate nohighlight">\(Y\)</span>. This means,
given <span class="math notranslate nohighlight">\(Y=1\)</span>, the probability that both tests come back positive is the product of the probabilities that each test comes back positive.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}(\hat{Y}_1 = 1, \hat{Y}_2 = 1 \mid Y = 1) =&amp; \mathbb{P}(\hat{Y}_1 = 1 \mid Y = 1) \mathbb{P}(\hat{Y}_2 = 1 \mid Y = 1) \\
=&amp; 1 \times 0.98 \\
=&amp; 0.98
\end{aligned}
\end{split}\]</div>
<p>We now need to compute <span class="math notranslate nohighlight">\(P(\hat{Y}_1 = 1, \hat{Y}_2 = 1)\)</span>, which is the marginal probability of both tests coming back positive. We can use the law of total probability to compute this.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}(\hat{Y}_1 = 1, \hat{Y}_2 = 1) =&amp; \mathbb{P}(\hat{Y}_1 = 1, \hat{Y}_2 = 1, Y = 1) + \mathbb{P}(\hat{Y}_1 = 1, \hat{Y}_2 = 1, Y = 0) \\
=&amp; \mathbb{P}(\hat{Y}_1 = 1, \hat{Y}_2 = 1 \mid Y = 1) \mathbb{P}(Y = 1) + \mathbb{P}(\hat{Y}_1 = 1, \hat{Y}_2 = 1 \mid Y = 0) \mathbb{P}(Y = 0) \\
=&amp; 0.98 \times 0.0015 + 0.0003 \times 0.9985 \\
=&amp; 0.00176955
\end{aligned}
\end{split}\]</div>
<p>Note that <span class="math notranslate nohighlight">\(\mathbb{P}(\hat{Y}_1 = 1, \hat{Y}_2 = 1 \mid Y = 0)\)</span> is calculated similarly using
the conditional independence assumption.</p>
<p>Finally, we can compute the probability that the patient has HIV given that both tests come back positive.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathbb{P}(Y = 1 \mid \hat{Y}_1 = 1, \hat{Y}_2 = 1) =&amp; \frac{0.98 \times 0.0015}{0.00176955} \\
=&amp; 0.8307
\end{aligned}
\end{split}\]</div>
<p>That is, the second test allowed us to gain much higher confidence that not all is well.
Despite the second test being considerably less accurate than the first one,
it still significantly improved our estimate.
The assumption of both tests being conditional independent of each other
was crucial for our ability to generate a more accurate estimate.
Take the extreme case where we run the same test twice.
In this situation we would expect the same outcome in both times,
hence no additional insight is gained from running the same test again.
The astute reader might have noticed that the diagnosis behaved
like a classifier hiding in plain sight
where our ability to decide whether a patient is healthy
increases as we obtain more features (test outcomes).</p>
</section>
<section id="simplified-probit-model">
<span id="id1"></span><h2>Simplified Probit Model<a class="headerlink" href="#simplified-probit-model" title="Permalink to this headline">#</a></h2>
<p>This example is taken from <span id="id2">[<a class="reference internal" href="../../references_and_resources/bibliography.html#id2" title="Stanley H. Chan. Introduction to probability for Data Science. Michigan Publishing, 2021.">Chan, 2021</a>]</span>, section 5.3.2, example 5.20.</p>
<p>Let <span class="math notranslate nohighlight">\(X\)</span> be a random bit such that</p>
<div class="math notranslate nohighlight">
\[\begin{split}
X= \begin{cases}+1, &amp; \text { with prob } 1 / 2 \\ -1, &amp; \text { with prob } 1 / 2\end{cases}
\end{split}\]</div>
<p>Suppose that <span class="math notranslate nohighlight">\(X\)</span> is transmitted over a noisy channel so that the observed signal is</p>
<div class="math notranslate nohighlight">
\[
Y=X+N,
\]</div>
<p>where <span class="math notranslate nohighlight">\(N \sim \operatorname{Gaussian}(0,1)\)</span> is the noise, which is independent of the signal <span class="math notranslate nohighlight">\(X\)</span>. Find the probabilities <span class="math notranslate nohighlight">\(\mathbb{P}[X=+1 \mid Y&gt;0]\)</span> and <span class="math notranslate nohighlight">\(\mathbb{P}[X=-1 \mid Y&gt;0]\)</span>.</p>
<ol>
<li><p><span class="math notranslate nohighlight">\(Y=X+N\)</span> such that <span class="math notranslate nohighlight">\(N\)</span> is a normal random variable with mean 0 and variance 1.</p>
<ol class="simple">
<li><p>Note that <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(N\)</span> are independent by definition. This means that <span class="math notranslate nohighlight">\(N\)</span> happening does
not change the probability of <span class="math notranslate nohighlight">\(X\)</span> happening. Ask why <span class="math notranslate nohighlight">\(N = Y - X\)</span> does not imply that <span class="math notranslate nohighlight">\(X\)</span>
is dependent on <span class="math notranslate nohighlight">\(N\)</span>.</p></li>
<li><p>Note that <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are <strong>not</strong> independent. Can we justify or our intuition is wrong.</p></li>
</ol>
</li>
<li><p>To find <span class="math notranslate nohighlight">\(P[X=1 | Y&gt;0]\)</span>, we need the following:</p>
<ol class="simple">
<li><p>We first recall that to find the conditional probability, we need to find the conditional PDF <span class="math notranslate nohighlight">\(f_{X|Y}(x|y)\)</span> first, or more concretely, <span class="math notranslate nohighlight">\(f_{X|Y}(x=1|y&gt;0)\)</span>.</p></li>
<li><p>We first note <span class="math notranslate nohighlight">\(f_{X|Y}(x|y) = \frac{f_{X,Y}(x,y)}{f_Y(y)}\)</span>.</p></li>
<li><p>This is by definition of conditional probability. We can see that in  section 5.3.1 and also in the chapter on conditional probability.</p></li>
<li><p>In particular, note that <span class="math notranslate nohighlight">\(f_{X, Y}(x, y) = f_X(x) \cap f_Y(y)\)</span>, so it is indeed the numerator of the conditional probability.</p></li>
<li><p>Overall, it is not clear how to find <span class="math notranslate nohighlight">\(f_Y(y)\)</span>, though we can find <span class="math notranslate nohighlight">\(f_X(x)\)</span>.</p></li>
<li><p>We will leave finding the denominator for later.</p></li>
<li><p>Note that <span class="math notranslate nohighlight">\(P[X=1|Y&gt;0]\)</span> is equivalent to integrating <span class="math notranslate nohighlight">\(f_{X|Y}(x=+1|y&gt;0)\)</span> for all <span class="math notranslate nohighlight">\(y&gt;0\)</span>. But we will soon hit a wall when we try to find an expression form for this PDF, furthermore, we could make use of the fact that the marginal PDF of <span class="math notranslate nohighlight">\(X\)</span> is given to solve this problem.</p></li>
<li><p>Now we instead use Bayes to say that</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
    P[X=+1|Y&gt;0] = \dfrac{P[Y&gt;0|X=+1]P[X=+1]}{P[Y&gt;0]}
    \]</div>
<p>which translates to finding the RHS of the equation. Note the numerator is a consequence of <span class="math notranslate nohighlight">\(P(X = +1, Y &gt; 0) = P(Y &gt; 0 | X = +1)P(X = +1)\)</span>, which is the definition of conditional probability. The denominator is the marginal probability of <span class="math notranslate nohighlight">\(Y&gt;0\)</span>, which we will find later.</p>
<ol class="simple">
<li><p>Note <span class="math notranslate nohighlight">\(P[X=+1]\)</span> is trivially equals to <span class="math notranslate nohighlight">\(\frac{1}{2}\)</span>, since <span class="math notranslate nohighlight">\(X\)</span> is a Bernoulli random variable with <span class="math notranslate nohighlight">\(p=0.5\)</span>. Even though it is not mentioned explicitly, we can assume that <span class="math notranslate nohighlight">\(X\)</span> is a Bernoulli random variable with <span class="math notranslate nohighlight">\(p=0.5\)</span> since it does seem to fulfil the definition of a Bernoulli random variable provided it is independent trials.</p></li>
<li><p>Now to find <span class="math notranslate nohighlight">\(P[Y&gt;0|X=+1]\)</span>, we need to find <span class="math notranslate nohighlight">\(f_{Y|X}(y&gt;0|x=+1)\)</span>.</p></li>
</ol>
</li>
<li><p>To find the conditional distribution <span class="math notranslate nohighlight">\(f_{Y|X}(y&gt;0|x=+1)\)</span>, we first must be clear that this is a conditional PDF and not a probability yet, i.e. <span class="math notranslate nohighlight">\(P[Y&gt;0|X=1]\)</span> is found by integrating this PDF! We must also be clear that this probability is all about <span class="math notranslate nohighlight">\(y\)</span> and therefore we will integrate over <span class="math notranslate nohighlight">\(dy\)</span> only instead of the usual double integral. Why? Because we are given <span class="math notranslate nohighlight">\(X=+1\)</span>, this means <span class="math notranslate nohighlight">\(X\)</span> is fixed and there is nothing <em><strong>random</strong></em> about it, you can imagine in the 2D (3D) space PDF where the axis <span class="math notranslate nohighlight">\(X\)</span> is fixed at 1, and we are integrating over the curve under <span class="math notranslate nohighlight">\(Y&gt;0\)</span> with <span class="math notranslate nohighlight">\(X=1\)</span>, i.e. <span class="math notranslate nohighlight">\((x=1, y=0.1), (x=1, y=0.2), \ldots\)</span></p>
<ol class="simple">
<li><p>Now the difficult question is what is <span class="math notranslate nohighlight">\(f_{Y|X}(y&gt;0|x=1)\)</span>? We can find clues by looking at the equation <span class="math notranslate nohighlight">\(Y=X+N\)</span>. In laymen terms, <span class="math notranslate nohighlight">\(Y=X+N\)</span> means what is <span class="math notranslate nohighlight">\(Y\)</span> given <span class="math notranslate nohighlight">\(X=1\)</span>? So we can simplify <span class="math notranslate nohighlight">\(Y=X+N\)</span> to <span class="math notranslate nohighlight">\(Y=1+N\)</span>. We emphasise that this PDF is a function of <span class="math notranslate nohighlight">\(y\)</span> only, and not <span class="math notranslate nohighlight">\(x\)</span>. But this does not mean <span class="math notranslate nohighlight">\(f_{Y|X} = f_Y\)</span>, which we will soon see.</p></li>
<li><p>Next, by the definition of shifting (linear transformation), if <span class="math notranslate nohighlight">\(N\)</span> is a normal random variable of mean <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>, then shifting it by <span class="math notranslate nohighlight">\(1\)</span> merely shifts the mean by <span class="math notranslate nohighlight">\(1\)</span> and the variance remains the same <a class="footnote-reference brackets" href="#id4" id="id3">1</a>. This shows that <span class="math notranslate nohighlight">\(Y\)</span> is actually still a gaussian family, same as <span class="math notranslate nohighlight">\(N\)</span>, but with a different mean and same variance.</p></li>
<li><p>Therefore, <span class="math notranslate nohighlight">\(Y=1+N\)</span> is a normal random variable with mean <span class="math notranslate nohighlight">\(1+\mu\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>, <span class="math notranslate nohighlight">\(Y \sim \mathcal{N}(1+\mu, \sigma^2)\)</span>. With <span class="math notranslate nohighlight">\(\mu=0\)</span> and <span class="math notranslate nohighlight">\(\sigma=1\)</span>, we have <span class="math notranslate nohighlight">\(Y \sim \mathcal{N}(1, 1)\)</span>.</p></li>
<li><p>Now we can find <span class="math notranslate nohighlight">\(f_{Y|X}(y&gt;0|x=1)\)</span> by plugging in <span class="math notranslate nohighlight">\(y&gt;0\)</span> into the PDF of <span class="math notranslate nohighlight">\(\mathcal{N}(1, 1)\)</span>, which is <span class="math notranslate nohighlight">\(f_{Y|X}(y&gt;0|x=1) = \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}(y-1)^2}\)</span>. Note that this is a PDF, not a probability yet.</p></li>
<li><p>To recover the probability, we must integrate over <span class="math notranslate nohighlight">\(dy\)</span>.</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
    P[Y&gt;0|X=1] = \int_{y&gt;0} \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}(y-1)^2} dy = \int_{0}^{\infty} \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}(y-1)^2} dy
    \]</div>
<p>this is because <span class="math notranslate nohighlight">\(y&gt;0\)</span> is equivalent to <span class="math notranslate nohighlight">\(0&lt;y&lt;\infty\)</span>.</p>
<ol class="simple">
<li><p>We can now use the standard normal table to find the probability, which is <span class="math notranslate nohighlight">\(0.8413\)</span>. See chan’s solution which is <span class="math notranslate nohighlight">\(1 - \Phi(-1) = 0.8413\)</span>.</p></li>
<li><p>Similarly, we can find <span class="math notranslate nohighlight">\(P[Y&gt;0|X=-1]\)</span> by plugging in <span class="math notranslate nohighlight">\(y&gt;0\)</span> into the PDF of <span class="math notranslate nohighlight">\(\mathcal{N}(-1, 1)\)</span>, which is <span class="math notranslate nohighlight">\(f_{Y|X}(y&gt;0|x=-1) = \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}(y+1)^2}\)</span>. We can then integrate over <span class="math notranslate nohighlight">\(y&gt;0\)</span> to find the probability, <span class="math notranslate nohighlight">\(1-\Phi(1)\)</span>.</p></li>
</ol>
</li>
<li><p>As of now, we have recovered <span class="math notranslate nohighlight">\(P[X=+1]\)</span> and <span class="math notranslate nohighlight">\(P[Y&gt;0|X=+1]\)</span>, what is left is the denominator <span class="math notranslate nohighlight">\(P[Y&gt;0]\)</span>. By the law of total probability, we have</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \begin{aligned}
        P[Y&gt;0] &amp;= P[Y&gt;0|X=+1]P[X=+1] \\
        &amp;+ P[Y&gt;0|X=-1]P[X=-1]
    \end{aligned}
    \end{split}\]</div>
<p>which is <span class="math notranslate nohighlight">\(0.8413 \times 0.5 + 0.1587 \times 0.5 = 0.5\)</span>.</p>
</li>
<li><p>Finally, we can now recover <span class="math notranslate nohighlight">\(P[X=+1|Y&gt;0]\)</span> by plugging in the values we have found.</p>
<div class="math notranslate nohighlight">
\[
    P[X=+1|Y&gt;0] = \dfrac{P[Y&gt;0|X=+1]P[X=+1]}{P[Y&gt;0]} = \dfrac{0.8413 \times 0.5}{0.5} = 0.8413
    \]</div>
<p>which is the same as the answer given in the question.</p>
</li>
<li><p>Last but not least, to find <span class="math notranslate nohighlight">\(P[X=-1|Y&gt;0]\)</span>, it is simply the complement of <span class="math notranslate nohighlight">\(P[X=+1|Y&gt;0]\)</span>, which is <span class="math notranslate nohighlight">\(1 - 0.8413 = 0.1587\)</span>.</p>
<div class="math notranslate nohighlight">
\[
    P[X=-1|Y&gt;0] = 1 - P[X=+1|Y&gt;0] = 1 - 0.8413 = 0.1587
    \]</div>
<p>which is the same as the answer given in the question.</p>
</li>
</ol>
<hr class="footnotes docutils" />
<dl class="footnote brackets">
<dt class="label" id="id4"><span class="brackets"><a class="fn-backref" href="#id3">1</a></span></dt>
<dd><p>You can easily plot it out to see that the bell curve shifting 1 on the x axis merely shifts the curve right by 1, and since mean is the center of the bell curve, the mean is shifted by 1. The variance remains the same because the bell curve is symmetric about the mean, and the variance is the width of the bell curve, which remains unchanged.</p>
</dd>
</dl>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./05_joint_distributions/0503_conditional_pmf_pdf"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="concept.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Concept</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../0504_conditional_expectation_variance/intro.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Conditional Expectation and Variance</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Gao Hongnan<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>