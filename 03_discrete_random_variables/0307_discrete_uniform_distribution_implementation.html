
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Implementation &#8212; Probability &amp; Statistics</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script src="../_static/tabs.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"defeq": "\\overset{\\text{def}}{=}", "defa": "\\overset{\\text{(a)}}{=}", "defb": "\\overset{\\text{(b)}}{=}", "defc": "\\overset{\\text{(c)}}{=}", "defd": "\\overset{\\text{(d)}}{=}", "st": "\\mid", "mod": "\\mid", "S": "\\Omega", "s": "\\omega", "e": "\\exp", "P": "\\mathbb{P}", "R": "\\mathbb{R}", "expectation": "\\mathbb{E}", "v": "\\mathbf{v}", "a": "\\mathbf{a}", "b": "\\mathbf{b}", "c": "\\mathbf{c}", "u": "\\mathbf{u}", "w": "\\mathbf{w}", "x": "\\mathbf{x}", "y": "\\mathbf{y}", "z": "\\mathbf{z}", "0": "\\mathbf{0}", "1": "\\mathbf{1}", "A": "\\mathbf{A}", "B": "\\mathbf{B}", "C": "\\mathbf{C}", "E": "\\mathcal{F}", "lset": "\\left\\{", "rset": "\\right\\}", "lsq": "\\left[", "rsq": "\\right]", "lpar": "\\left(", "rpar": "\\right)", "lcurl": "\\left\\{", "rcurl": "\\right\\}", "pmf": "p_X", "pdf": "f_X", "pdftwo": "f_{X,Y}", "pdfjoint": "f_{\\mathbf{X}}", "cdf": "F_X", "pspace": "(\\Omega, \\mathcal{F}, \\mathbb{P})", "var": "\\operatorname{Var}", "std": "\\operatorname{Std}", "bern": "\\operatorname{Bernoulli}", "binomial": "\\operatorname{Binomial}", "geometric": "\\operatorname{Geometric}", "poisson": "\\operatorname{Poisson}", "uniform": "\\operatorname{Uniform}", "normal": "\\operatorname{Normal}", "gaussian": "\\operatorname{Gaussian}", "gaussiansymbol": "\\mathcal{N}", "exponential": "\\operatorname{Exponential}", "iid": "\\textbf{i.i.d.}"}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Bernoulli Distribution" href="0308_bernoulli_distribution_concept.html" />
    <link rel="prev" title="Discrete Uniform Distribution" href="0307_discrete_uniform_distribution_concept.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Probability & Statistics</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter 1. Mathematical Preliminaries
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../01_mathematical_preliminaries/01_combinatorics.html">
   Permutations and Combinations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../01_mathematical_preliminaries/02_calculus.html">
   Calculus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../01_mathematical_preliminaries/exercises.html">
   Exercises
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter 2. Probability
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../02_probability/0202_probability_space.html">
   Probability Space
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../02_probability/0203_probability_axioms.html">
   Probability Axioms
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../02_probability/0204_conditional_probability.html">
   Conditional Probability
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../02_probability/0205_independence.html">
   Independence
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../02_probability/0206_bayes_theorem.html">
   Baye’s Theorem and the Law of Total Probability
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../02_probability/summary.html">
   Summary
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter 3. Discrete Random Variables
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="0301_random_variables.html">
   Random Variables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="0302_discrete_random_variables.html">
   Discrete Random Variables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="0303_probability_mass_function.html">
   Probability Mass Function
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="0304_cumulative_distribution_function.html">
   Cumulative Distribution Function
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="0305_expectation.html">
   Expectation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="0306_moments_and_variance.html">
   Moments and Variance
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="0307_discrete_uniform_distribution_concept.html">
   Discrete Uniform Distribution
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Implementation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="0308_bernoulli_distribution_concept.html">
   Bernoulli Distribution
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="0308_bernoulli_distribution_implementation.html">
     Implementation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="iid.html">
   Independent and Identically Distributed (IID)
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="0309_binomial_distribution_concept.html">
   Binomial Distribution
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="0309_binomial_distribution_implementation.html">
     Implementation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="0309_binomial_distribution_application.html">
     Real World Examples
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="0310_geometric_distribution_concept.html">
   Geometric Distribution
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="0311_poisson_distribution_concept.html">
   Poisson Distribution
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="0311_poisson_distribution_implementation.html">
     Implementation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="summary.html">
   Important
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="exercises.html">
   Exercises
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter 4. Continuous Random Variables
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../04_continuous_random_variables/from_discrete_to_continuous.html">
   From Discrete to Continuous
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../04_continuous_random_variables/0401_continuous_random_variables.html">
   Continuous Random Variables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../04_continuous_random_variables/0402_probability_density_function.html">
   Probability Density Function
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../04_continuous_random_variables/0403_expectation.html">
   Expectation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../04_continuous_random_variables/0404_moments_and_variance.html">
   Moments and Variance
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../04_continuous_random_variables/0405_cumulative_distribution_function.html">
   Cumulative Distribution Function
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../04_continuous_random_variables/0406_mean_median_mode.html">
   Mean, Median and Mode
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../04_continuous_random_variables/0407_continuous_uniform_distribution.html">
   Continuous Uniform Distribution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../04_continuous_random_variables/0408_exponential_distribution.html">
   Exponential Distribution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../04_continuous_random_variables/0409_gaussian_distribution.html">
   Gaussian Distribution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../04_continuous_random_variables/0410_skewness_and_kurtosis.html">
   Skewness and Kurtosis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../04_continuous_random_variables/0411_convolve_and_sum_of_random_variables.html">
   Convolution and Sum of Random Variables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../04_continuous_random_variables/0412_functions_of_random_variables.html">
   Functions of Random Variables
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter 5. Joint Distributions
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../05_joint_distributions/braindump.html">
   Brain Dump
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../05_joint_distributions/naive_bayes.html">
   Naive Bayes
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  References and Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../references_and_resources/bibliography.html">
   Bibliography
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../references_and_resources/resources.html">
   Resources
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/gao-hongnan/gaohn-probability-stats/main?urlpath=tree/content/03_discrete_random_variables/0307_discrete_uniform_distribution_implementation.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/gao-hongnan/gaohn-probability-stats/blob/main/content/03_discrete_random_variables/0307_discrete_uniform_distribution_implementation.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/gao-hongnan/gaohn-probability-stats"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/gao-hongnan/gaohn-probability-stats/issues/new?title=Issue%20on%20page%20%2F03_discrete_random_variables/0307_discrete_uniform_distribution_implementation.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/03_discrete_random_variables/0307_discrete_uniform_distribution_implementation.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#utilities">
   Utilities
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-setup">
   The Setup
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ideal-histogram-distribution-pmf-vs-empirical-histogram-distribution">
   Ideal Histogram/Distribution (PMF) vs Empirical Histogram/Distribution
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Implementation</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#utilities">
   Utilities
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-setup">
   The Setup
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ideal-histogram-distribution-pmf-vs-empirical-histogram-distribution">
   Ideal Histogram/Distribution (PMF) vs Empirical Histogram/Distribution
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="implementation">
<h1>Implementation<a class="headerlink" href="#implementation" title="Permalink to this headline">#</a></h1>
<section id="utilities">
<h2>Utilities<a class="headerlink" href="#utilities" title="Permalink to this headline">#</a></h2>
<p>We will also use NumPy to create various input ranges and Matplotlib to visualize various functions:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import sys
from pathlib import Path
parent_dir = str(Path().resolve().parent)
sys.path.append(parent_dir)

import random
import warnings

import matplotlib.pyplot as plt
import numpy as np
import scipy.stats as stats

warnings.filterwarnings(&quot;ignore&quot;, category=DeprecationWarning)
%matplotlib inline

from utils import seed_all
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>seed_all(42)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Using Seed Number 42
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># create a true population of 1000 people with equal heights across 1-10cm
true_population = np.arange(1, 11, 1).repeat(100)
</pre></div>
</div>
</div>
</div>
<p>Both are the same but it is to differentiate between true and empirical.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def true_pmf(x: float, population: np.ndarray) -&gt; float:
    &quot;&quot;&quot;PMF of the true population: map X(\S) to a probability.
    
    Note:
        The PMF is completely determined if we know the true distribution.
    &quot;&quot;&quot;
    return np.sum(population == x) / len(population)

def empirical_pmf(x: float, sample: np.ndarray):
    &quot;&quot;&quot;Empirical distribution of the sample.&quot;&quot;&quot;
    return np.sum(sample == x) / len(sample)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># 1. What is the probability of selecting a person of height 1cm?
print(f&quot;P(X=1) = {true_pmf(1, true_population)}&quot;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>P(X=1) = 0.1
</pre></div>
</div>
</div>
</div>
</section>
<section id="the-setup">
<h2>The Setup<a class="headerlink" href="#the-setup" title="Permalink to this headline">#</a></h2>
<p>Let the true population be defined as a total of <span class="math notranslate nohighlight">\(1000\)</span> people. We imagine that <span class="math notranslate nohighlight">\(1000\)</span> is all the
people in the world/universe.</p>
<p>Amongst the 1000 people, 100 people is of height 1cm, 100 people is of height 2cm, 100 people is of height 3cm,
this holds true for all heights from 1cm to 10cm. We will assume that there are only 10 distinct heights
that people can be. Thus, this is a <strong>discrete</strong> distribution.</p>
<p>Let the experiment be a triplet <span class="math notranslate nohighlight">\(\pspace\)</span>, this experiment is the action of <em><strong>randomly selecting</strong></em>
a person from the true population.</p>
<p>Since our problem is about the height of the person, it is reasonable to define our <strong>sample space</strong>
to be <span class="math notranslate nohighlight">\(\Omega = \{1,2,3,4,5,6,7,8,9,10\}\)</span>, where each element of the sample space is the <strong>outcome</strong> of the <strong>experiment</strong>.
Note that our sample space is discrete and there are only 10 distinct outcomes.</p>
<p>Now suppose I want to answer a few simple questions about the experiment. For example, I want to know</p>
<ol class="simple">
<li><p>What is the probability of selecting a person of height 1cm?</p></li>
<li><p>What is the probability of selecting a person that is taller than 5cm (i.e. height 6cm, 7cm, 8cm, 9cm, 10cm)?</p></li>
<li><p>What is the mean height of the true population (expected value)?</p></li>
</ol>
<p>With that, we will need to define a random variable <span class="math notranslate nohighlight">\(X\)</span> and let <span class="math notranslate nohighlight">\(X\)</span> be the height of a <strong>randomly</strong> selected person from the <strong>true population</strong>.</p>
<p>In <a class="reference internal" href="0301_random_variables.html#random_variables">Definition 12</a>, <span class="math notranslate nohighlight">\(X\)</span> is a function <span class="math notranslate nohighlight">\(X: \Omega \rightarrow \mathbb{R}\)</span> which
maps an outcome <span class="math notranslate nohighlight">\(\xi \in \S\)</span> to a real number <span class="math notranslate nohighlight">\(X(\xi) \in \R\)</span>. This is needed if your outcomes are not
numerical. We first check if there is a need to
define a new mapping from <span class="math notranslate nohighlight">\(\Omega\)</span> to <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>. It turns out that we can just use the identity mapping
since the sample space <span class="math notranslate nohighlight">\(\Omega\)</span> is already a subset of <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>, and are just numbers. With that,
<span class="math notranslate nohighlight">\(X(\S)\)</span> is <span class="math notranslate nohighlight">\(\{1,2,3,4,5,6,7,8,9,10\}\)</span>.</p>
<p>With <span class="math notranslate nohighlight">\(X(\S)\)</span> defined, the <em><strong>state space</strong></em> (the range) is defined as per <a class="reference internal" href="0303_probability_mass_function.html#def_state_space">Definition 16</a>, we can associate each state
<span class="math notranslate nohighlight">\(x \in X(\S)\)</span> with a probability <span class="math notranslate nohighlight">\(P(X = x)\)</span>. This is the <em><strong>probability mass function</strong></em> (PMF) of <span class="math notranslate nohighlight">\(X\)</span>.</p>
<p>We can plot an ideal histogram to see the distribution of how the height of each person in the true population is distributed.</p>
<p>We call this an <strong>ideal histogram</strong> because we know the true population, and we are plotting every single person’s height in this true population.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def plot_true_pmf(population: np.ndarray):
    &quot;&quot;&quot;Plots the PMF of the true population.&quot;&quot;&quot;
    bins = np.arange(1, population.max() + 1.5) - 0.5
    fig, ax = plt.subplots()
    _ = ax.hist(
        population,
        bins,
        density=True,
        color=&quot;#0504AA&quot;,
        alpha=0.5,
        edgecolor=&quot;black&quot;,
        linewidth=2,
    )
    _ = ax.stem(
        population,
        [true_pmf(x, population) for x in population],
        linefmt=&quot;C3-&quot;,
        markerfmt=&quot;C3o&quot;,
        basefmt=&quot;C3-&quot;,
        use_line_collection=True,
    )

    _ = ax.set_xlabel(&quot;Height (cm)&quot;)
    _ = ax.set_ylabel(&quot;Probability&quot;)
    _ = ax.set_title(&quot;PMF of the true population&quot;)
    _ = ax.set_xticks(bins + 0.5)

    return fig, ax
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>_ = plot_true_pmf(true_population)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/0307_discrete_uniform_distribution_implementation_12_0.png" src="../_images/0307_discrete_uniform_distribution_implementation_12_0.png" />
</div>
</div>
<p>The above is the ideal histogram, which is the PMF. More concretely, for each
state <span class="math notranslate nohighlight">\(x \in X(\S)\)</span>, the probability of <span class="math notranslate nohighlight">\(X\)</span> being <span class="math notranslate nohighlight">\(x\)</span> is <span class="math notranslate nohighlight">\(P(X = x) = 1/10\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\P(X=x) = \begin{cases}
\frac{1}{10} \text{ if } x=1 \\
\frac{1}{10} \text{ if } x=2 \\
\frac{1}{10} \text{ if } x=3 \\
\vdots \\
\frac{1}{10} \text{ if } x=10 \\
\end{cases}
\end{align}
\end{split}\]</div>
<p>Now recall that the PMF is a probability distribution and is <em><strong>deteministic</strong></em>. There is
nothing random about the PMF since we defined it according to the true population. In other words,
the true population, our “universe”, has enumerated all the possible states and their probabilities.</p>
<p>With PMF, we can also answer questions 1,2 and 3.</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(\P(X=1) = \frac{1}{10} = 0.1\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\P(X &gt; 5) = \P(X=6) + \P(X=7) + \P(X=8) + \P(X=9) + \P(X=10) = \frac{5}{10} = 0.5\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\exp \lsq X \rsq = \sum_{x \in X(\S)} x \cdot \P(X=x) = \frac{1}{10} \cdot 1 + \frac{1}{10} \cdot 2 + \frac{1}{10} \cdot 3 + \cdots + \frac{1}{10} \cdot 10 = 5.5\)</span></p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># 1. What is the probability of selecting a person of height 1cm?
print(f&quot;P(X=1) = {true_pmf(1, true_population)}&quot;)

# 2. What is the probability of selecting a person that is taller than 5cm?
print(f&quot;P(X&gt;5) = {true_pmf(6, true_population) + true_pmf(7, true_population) + true_pmf(8, true_population) + true_pmf(9, true_population) + true_pmf(10, true_population)}&quot;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>P(X=1) = 0.1
P(X&gt;5) = 0.5
</pre></div>
</div>
</div>
</div>
<p>We can also say that <span class="math notranslate nohighlight">\(X\)</span> follows a <strong>discrete uniform distribution</strong>, <span class="math notranslate nohighlight">\(X \sim U(1,10)\)</span>.
This is also true because in probability theory and statistics,
the discrete uniform distribution is a symmetric probability distribution wherein a finite number of
values are equally likely to be observed; every one of <span class="math notranslate nohighlight">\(n\)</span> values has equal probability <span class="math notranslate nohighlight">\(\frac{1}{n}\)</span>.</p>
<p>Now connecting this concept back to <span id="id1">[<a class="reference internal" href="../references_and_resources/bibliography.html#id2" title="Stanley H. Chan. Introduction to probability for Data Science. Michigan Publishing, 2021.">Chan, 2021</a>]</span> chapter 3.2.4 on PMF vs empirical histogram. The idea seems
more apparent now.</p>
<figure class="align-default" id="fig-generative-vs-inference">
<img alt="../_images/generative_vs_inference.PNG" src="../_images/generative_vs_inference.PNG" />
<figcaption>
<p><span class="caption-number">Fig. 5 </span><span class="caption-text">Generative vs Inference, credits to <span id="id2">[<a class="reference internal" href="../references_and_resources/bibliography.html#id2" title="Stanley H. Chan. Introduction to probability for Data Science. Michigan Publishing, 2021.">Chan, 2021</a>]</span></span><a class="headerlink" href="#fig-generative-vs-inference" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Given a PMF and an associated random variable <span class="math notranslate nohighlight">\(X\)</span>, we can generate a sample of size <span class="math notranslate nohighlight">\(n\)</span> from the PMF.
This process is called <strong>synthesis</strong> <em><strong>if</strong></em> we know the true PMF, then we can generate more data
from the true population to train a model. This part is slightly confusing because if we know
the true PMF, should we not have all the data in the true population? This is often not true
in the real world as we won’t be able to enumerate all the possible states and their probabilities.
What we can do is to assume that the underlying distribution follows a certain distribution (say Gaussian),
then we can generate data from this distribution. This is called <strong>synthesis</strong> and <strong>generative modelling</strong>.
The key here is we are sure of the underlying distribution, and we can generate data from it (<strong>KIV as a bit confused here</strong>).</p>
<p>In contrast, the more common case is that we do not know the true PMF. We only have a sample of size <span class="math notranslate nohighlight">\(n\)</span> from
the true population. We are given a dataset by our stakeholders, and then we want to estimate the
PMF. This process is called <strong>estimate/inference</strong>.
In our current example, this is not very
obvious because an uniform distribution does not have parameters to estimate
(i.e. <a class="reference external" href="https://en.wikipedia.org/wiki/Discrete_uniform_distribution">non-parametric</a>).
But the key here is given a dataset sampled from the true population, we want to first <em><strong>propose</strong></em>
a reasonable <em><strong>model/distribution</strong></em>, and work towards estimating the parameters of this model/distribution.
For example, if we propose a Gaussian distribution, we can estimate the mean and standard deviation with the given
empirical dataset.</p>
</section>
<section id="ideal-histogram-distribution-pmf-vs-empirical-histogram-distribution">
<h2>Ideal Histogram/Distribution (PMF) vs Empirical Histogram/Distribution<a class="headerlink" href="#ideal-histogram-distribution-pmf-vs-empirical-histogram-distribution" title="Permalink to this headline">#</a></h2>
<p>But we can still make sense of it with the following example with uniform distribution even if it is non-parametric.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def plot_empirical_pmf(sample: np.ndarray):
    &quot;&quot;&quot;Plots the empirical histogram of a sample dataset drawn from the population.&quot;&quot;&quot;
    bins = np.arange(1, sample.max() + 1.5) - 0.5
    fig, ax = plt.subplots()
    _ = ax.hist(
        sample,
        bins,
        density=True,
        color=&quot;#0504AA&quot;,
        alpha=0.5,
        edgecolor=&quot;black&quot;,
        linewidth=2,
    )
    _ = ax.stem(
        sample,
        [empirical_pmf(x, sample) for x in sample],
        linefmt=&quot;C3-&quot;,
        markerfmt=&quot;C3o&quot;,
        basefmt=&quot;C3-&quot;,
        use_line_collection=True,
    )

    _ = ax.set_xlabel(&quot;Height (cm)&quot;)
    _ = ax.set_ylabel(&quot;Probability&quot;)
    _ = ax.set_title(f&quot;PMF of a sample of size {len(sample)}&quot;)
    _ = ax.set_xticks(bins + 0.5)

    return fig, ax
</pre></div>
</div>
</div>
</div>
<p>We now define 3 random samples of 100, 500 and 900 people drawn from the true population drawn uniformly at random with no replacement.</p>
<p><strong>TODO: no replacement means samples are dependent, but seems to be more accurate to illustrate a point?</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>sample_100 = np.random.choice(true_population, 100, replace=False)
sample_500 = np.random.choice(true_population, 500, replace=False)
sample_900 = np.random.choice(true_population, 900, replace=False)
</pre></div>
</div>
</div>
</div>
<p>We then plot their histogram and compare to the ideal histogram.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># ideal + empirical
fig, axs = plt.subplots(2, 2, figsize=(20, 10))
bins = np.arange(1, true_population.max() + 1.5) - 0.5
axs[0, 0].hist(
    true_population,
    bins,
    density=True,
    color=&quot;#0504AA&quot;,
    alpha=0.5,
    edgecolor=&quot;black&quot;,
    linewidth=2,
)
axs[0, 0].stem(
    true_population,
    [true_pmf(x, true_population) for x in true_population],
    linefmt=&quot;C3-&quot;,
    markerfmt=&quot;C3o&quot;,
    basefmt=&quot;C3-&quot;,
    use_line_collection=True,
)
axs[0, 0].set_title(&quot;PMF of the true population&quot;)
axs[0, 0].set_xlabel(&quot;Height (cm)&quot;)
axs[0, 0].set_ylabel(&quot;Probability&quot;)
axs[0, 0].set_xticks(bins + 0.5)

axs[0, 1].hist(
    sample_100,
    bins,
    density=True,
    color=&quot;#0504AA&quot;,
    alpha=0.5,
    edgecolor=&quot;black&quot;,
    linewidth=2,
)
axs[0, 1].stem(
    sample_100,
    [empirical_pmf(x, sample_100) for x in sample_100],
    linefmt=&quot;C3-&quot;,
    markerfmt=&quot;C3o&quot;,
    basefmt=&quot;C3-&quot;,
    use_line_collection=True,
)
axs[0, 1].set_title(&quot;PMF of a sample of size 100&quot;)
axs[0, 1].set_xlabel(&quot;Height (cm)&quot;)
axs[0, 1].set_ylabel(&quot;Probability&quot;)
axs[0, 1].set_xticks(bins + 0.5)

axs[1, 0].hist(
    sample_500,
    bins,
    density=True,
    color=&quot;#0504AA&quot;,
    alpha=0.5,
    edgecolor=&quot;black&quot;,
    linewidth=2,
)
axs[1, 0].stem(
    sample_500,
    [empirical_pmf(x, sample_500) for x in sample_500],
    linefmt=&quot;C3-&quot;,
    markerfmt=&quot;C3o&quot;,
    basefmt=&quot;C3-&quot;,
    use_line_collection=True,
)
axs[1, 0].set_title(&quot;PMF of a sample of size 500&quot;)
axs[1, 0].set_xlabel(&quot;Height (cm)&quot;)
axs[1, 0].set_ylabel(&quot;Probability&quot;)
axs[1, 0].set_xticks(bins + 0.5)

axs[1, 1].hist(
    sample_900,
    bins,
    density=True,
    color=&quot;#0504AA&quot;,
    alpha=0.5,
    edgecolor=&quot;black&quot;,
    linewidth=2,
)
axs[1, 1].stem(
    sample_900,
    [empirical_pmf(x, sample_900) for x in sample_900],
    linefmt=&quot;C3-&quot;,
    markerfmt=&quot;C3o&quot;,
    basefmt=&quot;C3-&quot;,
    use_line_collection=True,
)
axs[1, 1].set_title(&quot;PMF of a sample of size 900&quot;)
axs[1, 1].set_xlabel(&quot;Height (cm)&quot;)
axs[1, 1].set_ylabel(&quot;Probability&quot;)
axs[1, 1].set_xticks(bins + 0.5);
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/0307_discrete_uniform_distribution_implementation_22_0.png" src="../_images/0307_discrete_uniform_distribution_implementation_22_0.png" />
</div>
</div>
<ul class="simple">
<li><p>We can tell for the 100 samples, the empiricial histogram is not very close to the true pmf (true distribution).</p></li>
<li><p>We can tell for the 500 samples, the empiricial histogram is a bit closer to the true pmf (true distribution).</p></li>
<li><p>We can tell for the 900 samples, the empiricial histogram is very close to the true pmf (true distribution).</p></li>
</ul>
<p>Like what the professor said, if we take a large enough sample, it will be close to the true pmf
this is obvious if we take say 900 out of 1000, then it will be closer to the true pmf
simply because we have more representation across samples. Like
if we only take 100 samples, maybe we a bit unlucky and get only 1 sample of height 5cm, then
that empirical histogram will be very far from the true pmf since the prob of 5 cm in that
example became 1/100 = 0.01! In our case, if check <code class="docutils literal notranslate"><span class="pre">sorted(sample_100)</span></code>, there are only 6 people
with height 2 cm, so our empirical histogram tells us a empirical distribution of only <span class="math notranslate nohighlight">\(6/100 = 0.06\)</span>
of getting a person with 2 cm, which is very different from 0.1.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def expected_value(population: np.ndarray) -&gt; float:
    &quot;&quot;&quot;Expected value of the true population.&quot;&quot;&quot;
    return np.sum(population) / len(population)


def empirical_mean(sample: np.ndarray) -&gt; float:
    &quot;&quot;&quot;Empirical mean of the sample.&quot;&quot;&quot;
    return np.sum(sample) / len(sample)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># What is the mean height of the true population (expected value)?
print(f&quot;The expected value of the true population is {expected_value(true_population)}cm.&quot;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The expected value of the true population is 5.5cm.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>print(f&quot;The empirical mean of the sample size of 100 is {empirical_mean(sample_100)}cm.&quot;)
print(f&quot;The empirical mean of the sample size of 500 is {empirical_mean(sample_500)}cm.&quot;)
print(f&quot;The empirical mean of the sample size of 900 is {empirical_mean(sample_900)}cm.&quot;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The empirical mean of the sample size of 100 is 5.38cm.
The empirical mean of the sample size of 500 is 5.392cm.
The empirical mean of the sample size of 900 is 5.541111111111111cm.
</pre></div>
</div>
</div>
</div>
<p>The law of averages also make sense once you understood why more samples converge to the true pmf, the idea is the same,
as there are more samples, we get a more accurate representation of the true population, and therefore mean also more accurate.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># uvals2 = np.linspace(0, 6, 61)
# plt.step(uvals2, U.cdf(uvals2), where=&quot;post&quot;)

# plt.xlabel(&quot;$u$&quot;)
# plt.ylabel(&quot;$F_U(u)$&quot;);
</pre></div>
</div>
</div>
</div>
<p>Finally, let’s compare the cumulative histogram (with both <code class="docutils literal notranslate"><span class="pre">cumulative</span> <span class="pre">=</span> <span class="pre">True</span></code> and <code class="docutils literal notranslate"><span class="pre">density</span> <span class="pre">=</span> <span class="pre">True</span></code>) to the CDF:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># uvals2 = np.linspace(0, 6, 61)
# plt.step(uvals2, U.cdf(uvals2), where=&quot;post&quot;)
# plt.hist(u, cumulative=True, density=True, bins=newbins)

# plt.xlabel(&quot;$u$&quot;)
# plt.ylabel(&quot;$F_U(u)$&quot;);
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./03_discrete_random_variables"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="0307_discrete_uniform_distribution_concept.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Discrete Uniform Distribution</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="0308_bernoulli_distribution_concept.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Bernoulli Distribution</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Gao Hongnan<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>