{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a6b5588",
   "metadata": {},
   "source": [
    "# Important Brain Dump\n",
    "\n",
    "Some important stuff here which I need to remember and yet to be able to formalize.\n",
    "\n",
    "**Always refer to my example setup.**\n",
    "\n",
    "## Temp Writings\n",
    "\n",
    "```{prf:definition} Bernoulli Distribution\n",
    ":label: def:bernoulli\n",
    "\n",
    "Let $X$ be a **Bernoulli random variable** with parameter $p$. Then the \n",
    "probability mass function (PMF) of $X$ is given by \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\P(X=x) = \\begin{cases}\n",
    "p   &\\quad \\text{ if } x=1 \\\\\n",
    "1-p &\\quad \\text{ if } x=0 \\\\\n",
    "0   &\\quad \\text{ otherwise }\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $0 \\leq p \\leq 1$ is called the Bernoulli parameter. \n",
    "\n",
    "Some conventions:\n",
    "\n",
    "1. We denote $X \\sim \\bern(p)$ if $X$ follows a Bernoulli distribution with parameter $p$.\n",
    "2. The states of $X$ are $x \\in \\{0,1\\}$. This means $X$ only has two (binary) states, 0 and 1.\n",
    "3. We denote $1$ as **success** and $0$ as **failure** and consequently $p$ as the probability of success\n",
    "and $1-p$ as the probability of failure.\n",
    "4. Bear in mind that $X$ is defined over $\\pspace$, and when we say $\\P \\lsq X=x \\rsq$, we are also saying\n",
    "$\\P \\lsq E \\rsq$ where $E \\in \\E$. Imagine a coin toss, $E$ is the event that the coin lands on heads,\n",
    "which translates to $E = \\{X=1\\}$.\n",
    "```\n",
    "\n",
    "\n",
    "```{prf:property} Expectation of Bernoulli Distribution\n",
    ":label: prop:bernoulli\n",
    "\n",
    "Let $X \\sim \\bern(p)$ be a Bernoulli random variable with parameter $p$. Then the expectation of $X$ is given by\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\exp \\lsq X \\rsq = \\sum_{x \\in X(\\S)} x \\cdot \\P(X=x) = 1 \\cdot p + 0 \\cdot (1-p) = p\n",
    "\\end{align}\n",
    "$$\n",
    "```\n",
    "\n",
    "```{prf:property} Variance of Bernoulli Distribution\n",
    ":label: prop:bernoulli_var\n",
    "\n",
    "Let $X \\sim \\bern(p)$ be a Bernoulli random variable with parameter $p$. Then the variance of $X$ is given by\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\var \\lsq X \\rsq = \\sum_{x \\in X(\\S)} (x - \\exp \\lsq X \\rsq)^2 \\cdot \\P(X=x) = (1 - p)^2 \\cdot p + (0 - p)^2 \\cdot (1-p) = p(1-p)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "It can also be shown using the second moment of $X$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\var \\lsq X \\rsq = \\exp \\lsq X^2 \\rsq - \\exp \\lsq X \\rsq^2 = \\exp \\lsq X^2 \\rsq - p^2 = p(1-p)\n",
    "\\end{align}\n",
    "$$\n",
    "```\n",
    "\n",
    "\n",
    "## Maximum Variance \n",
    "\n",
    "### Minimum and Maximum Variance of Coin Toss\n",
    "\n",
    "This example is taken from {cite}`chan_2021`, page 140.\n",
    "\n",
    "Consider a coin toss, following a Bernoulli distribution. Define $X \\sim \\bern(p)$.\n",
    "\n",
    "If we toss the coin $n$ times, then we ask ourselves what is the minimum and maximum variance of the coin toss.\n",
    "\n",
    "Recall in {prf:ref}`def_variance` that the variance is basically how much the data deviates from the mean.\n",
    "\n",
    "If the coin is biased at $p=1$, then the variance is $0$ because the coin always lands on heads. The \n",
    "intuition is that the coin is \"deterministic\", and hence there is no variance at all. If the coin\n",
    "is biased at $p=0.9$, then there is a little variance, because the coin will consistently land on heads\n",
    "$90\\%$ of the time. If the coin is biased at $p=0.5$, then there is a lot of variance, because the coin\n",
    "is fair and has a 50-50 chance of landing on heads or tails. Though fair, the variance is maximum here.\n",
    "\n",
    "## Important Topics\n",
    "\n",
    "See {doc}`./03_discrete_random_variables/0307_discrete_uniform_distribution` for my whole setup.\n",
    "\n",
    "## The Empirical vs Theoretical Distribution Setup\n",
    "\n",
    "- https://inferentialthinking.com/chapters/intro.html\n",
    "- See {doc}`./03_discrete_random_variables/0307_discrete_uniform_distribution` for my whole setup.\n",
    "\n",
    "## The Problem\n",
    "\n",
    "### The ticket model and what is a r.v\n",
    "\n",
    "- https://stats.stackexchange.com/questions/50/what-is-meant-by-a-random-variable/54894#54894\n",
    "- https://stats.stackexchange.com/questions/68599/distribution-of-correlation-coefficient-between-two-discrete-random-variables-an/68782#68782\n",
    "\n",
    "- A true population, say the height of all people in the world. To simplify the problem imagine living in a world of people whose \n",
    "height is a whole number ranging from 1-100 cm, ok I know it is absurd but it is just for the sake of the example, since discrete numbers are easier to visualize.\n",
    "Also secretly imagine the population is 1000 people with 100 people of each height (important here as we will see later).\n",
    "- Imagine a ticket box called the \"population box\" which has a ticket for each person in the world.\n",
    "    - every person in the world write their height on a ticket and put it in the box.\n",
    "- So note that we can think the population box as our sample space, each ticket is an outcome.\n",
    "- Note that it can be the case that more than 1 ticket has the same height, so to be very concise, our population box not a \"set\", so not a sample space.\n",
    "- Now recall that a random variable is a function that maps outcomes to real numbers.\n",
    "- In our case if we treat $X: \\S \\to \\R$ as a r.v, then it is obvious that the sample space $\\S$ is all from 0 to 100\n",
    "and for this case our mapping to $\\R$ is just the identity function, since the height of a person is a real number ( a random variable is a way to assign a numerical code to each possible outcome).\n",
    "This aside, what is more important is that we say $X$ is a r.v. that represents the height of a person (when we pick 1 ticket).\n",
    "And the randomness comes from we don't know which ticket we pick, as it could be any person representing any height.\n",
    "But once **it is picked**, the **realization** of the r.v. is the height of the person, say hongnan with height 175 cm.\n",
    "\n",
    "### Why data points are considered random variables\n",
    "\n",
    "- See https://mathstat.slu.edu/~speegle/_book/SimulationRV.html\n",
    "- In ml context, Random variables $X_1, X_2, \\ldots X_{???}$ are the data points of the height of people, and the true population space is the set of all possible data points (in our case it is actually 1 million people).\n",
    "- I was confused because $X: \\S \\to \\R$ is a r.v. that represents the height of a person, say if $100 cm \\in \\S$, then $X(100) = 100 cm$ is the realized outcome.\n",
    "  Then why do we need to index the data points? Because the mapping of $X$ is already well defined for any outcome in $\\S$, so for each person in the world\n",
    "  we already can represent the single random variable $X$ that represents the height of that person. So why do we need to index the data points?\n",
    "- For example, most cited definition is the iid assumption: random variables $X_1, X_2, \\ldots X_{n}$ are called independent and identically distributed or iid if the variables are mutually independent, and each  \n",
    "$X_i$ has the same probability distribution. Say $n=10$ people. It turns out we should think of it this way, in the true population box, all the tickets (height) of the people\n",
    "are **numbered**, and each $X_i$ is actually remember is a deterministic answer after realization, and therefore the numbering makes sense. We treat each draw of the ticket as a random variable, and the numbering is just a way to index the random variables.\n",
    "- Furthermore, we usually take a random sample of size $n$ from the population box, and treat each draw as a rv.\n",
    "\n",
    "### Super important\n",
    "\n",
    "Above has a hazy concept, one one hand sample space is a set and therefore should be unique, but on the other hand, if there's 1000 people\n",
    "in the true population, and we treat the population box as the sample space, then the sample space is no longer \"unique\" since there are \n",
    "only 100 distinct heights? However, if we number the tickets, then the sample space is unique, in a way we are playing abuse of notation\n",
    "that two different people with the same height 175 cm are two distinct outcomes in the sample space. This is very important to realize!!!\n",
    "\n",
    "### Empirical distribution/histogram\n",
    "\n",
    "To put more concrete example, consider the same experiment above, define the rv $X$ to be the height of a person,\n",
    "then find probability of getting a person with height 175 cm, say $P(X=175) = ?$.\n",
    "\n",
    "To find this answer, we need to find PMF. Note PMF is ideal means it is deterministic and hinged upon the true population.\n",
    "\n",
    "So we secretly know the true PMF of the above distribution is actually simply \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\P(X=x) = \\frac{10}{1000} = \\frac{1}{10} \\quad \\forall x \\in \\{1, \\ldots, 100\\}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\P(X=x) = \\begin{cases}\n",
    "\\frac{1}{10} \\text{ if } x=1 \\\\\n",
    "\\frac{1}{10} \\text{ if } x=2 \\\\\n",
    "\\frac{1}{10} \\text{ if } x=3 \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{1}{10} \\text{ if } x=100 \\\\\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "since it is equally likely to get any person with height 1-100 cm over 1000 people. Note\n",
    "that for each height, we have exactly 10 people.\n",
    "\n",
    "Recall the \n",
    "example \n",
    "\n",
    "$$\n",
    "\\P(A) = \\dfrac{n(A)}{n(\\S)}\n",
    "$$\n",
    "\n",
    "and since our $\\S$ is 1000 people.\n",
    "\n",
    "Now we randomly pick 10 people from the true population, then we can plot a histogram of the heights of the 10 people, and the histogram\n",
    "says 3 people have height 175 cm, 2 people have height 180 cm, and so on. This is the empirical distribution, and it is not the true PMF,\n",
    "and in our case we have $\\dfrac{3}{10}$ probability that a person has 175cm $\\P(X=175) = \\dfrac{3}{10}$. But note carefully\n",
    "here is **empirical** distribution and is non-deterministic."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.11.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  },
  "mystnb": {
   "number_source_lines": true
  },
  "source_map": [
   16
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}