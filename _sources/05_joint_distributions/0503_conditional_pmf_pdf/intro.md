# Conditional PMF and PDF

## Introduction

This chapter is very important, as it is tightly coupled with Bayes' rule. In machine learning,
there are many model structure that stems from conditional distributions. For example, the target 
variable $Y$ is often conditioned on the input variable $\mathbf{X}$, and we are tasked to model
$\hat{Y}=\mathbb{P}(Y \mid \mathbf{X})$. 

## Learning Objectives

- To learn the distinction between a joint probability distribution and a conditional probability distribution.
- To recognize that a conditional probability distribution is simply a probability distribution for a sub-population.
- To learn the formal definition of a conditional probability mass function of a discrete r.v.  given a discrete r.v. .
- To learn how to calculate the conditional mean and conditional variance of a discrete r.v.  given a discrete r.v. .
- To be able to apply the methods learned in the lesson to new problems.